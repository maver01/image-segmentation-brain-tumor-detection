{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short pipeline\n",
    "\n",
    "Contains only the main code necessary to run this project. No additional visualisations or performance improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.offsetbox import (TextArea, DrawingArea, OffsetImage,\n",
    "                                  AnnotationBbox)\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir  = \"/home/maver02/Projects/Infrastructure_suite_project/Development/find-the-dog-project/CLOUD/data/image-segmentation-brain-tumor/\"\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image  Class\n",
       "0  Image1      0\n",
       "1  Image2      0\n",
       "2  Image3      1\n",
       "3  Image4      1\n",
       "4  Image5      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3762, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(base_dir + \"Brain Tumor.csv\"))[['Image', 'Class']]\n",
    "display(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Training + Validation with Testing Set\n",
    "def split_size(df, size):\n",
    "    \"\"\"\n",
    "    Calculate the split size based on the given fraction of the DataFrame length.\n",
    "    \"\"\"\n",
    "    return int(size * len(df))\n",
    "\n",
    "\n",
    "train_labels = df['Class'].values[:split_size(df, 0.8)]\n",
    "train_file_names = df['Image'].values[:split_size(df, 0.8)]\n",
    "\n",
    "val_labels = df['Class'].values[split_size(df, 0.8):split_size(df, 0.9)]\n",
    "val_file_names = df['Image'].values[split_size(df, 0.8):split_size(df, 0.9)]\n",
    "\n",
    "test_labels = df['Class'].values[split_size(df, 0.9):]\n",
    "test_file_names = df['Image'].values[split_size(df, 0.9):]\n",
    "\n",
    "# labels are arrays of 1 or 0, names are arrays of image file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Training + Validation with Testing Set\n",
    "def split_array_labels(arr_image, arr_label):\n",
    "    \"\"\"\n",
    "    Split the array of images and labels into two separate arrays based on the label.\n",
    "    \"\"\"\n",
    "    arr_image_0 = arr_image[np.where(arr_label==0)]\n",
    "    arr_image_1 = arr_image[np.where(arr_label==1)]\n",
    "    return {'0':arr_image_0, '1':arr_image_1}\n",
    "\n",
    "train_arr_dict = split_array_labels(train_file_names, train_labels)\n",
    "val_arr_dict = split_array_labels(val_file_names, val_labels)\n",
    "test_arr_dict = split_array_labels(test_file_names, test_labels)\n",
    "\n",
    "# each is a dictionary with keys '0' and '1', values are arrays of file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove old directories\n",
      "Created empty  training, validation and testing directories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created training, validation and testing directories containing images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create directories for training, validation and testing\n",
    "def create_empty_directories(base_dir):\n",
    "    # in case you want to run it several times, delete the directory and create new one\n",
    "    check_exist_path = os.path.join(base_dir, '_MODELLING')\n",
    "    if os.path.isdir(check_exist_path):\n",
    "        shutil.rmtree(check_exist_path)\n",
    "        print(\"Remove old directories\")\n",
    "    \n",
    "    for label in ['0','1']:\n",
    "        training_dir = os.path.join(base_dir, '_MODELLING', 'training', label)\n",
    "        validation_dir = os.path.join(base_dir, '_MODELLING', 'validation', label)\n",
    "        testing_dir = os.path.join(base_dir, '_MODELLING', 'testing', label)    \n",
    "        os.makedirs(training_dir)\n",
    "        os.makedirs(validation_dir)\n",
    "        os.makedirs(testing_dir)\n",
    "\n",
    "    print(f\"Created empty  training, validation and testing directories\")\n",
    "\n",
    "create_empty_directories(base_dir)\n",
    "\n",
    "# copy data into the directories\n",
    "def split_data(SOURCE_DIR, train_arr_dict, val_arr_dict, test_arr_dict):\n",
    "    for label in tqdm(['0','1']):\n",
    "        for file_name in train_arr_dict[label]:\n",
    "            file_name = f\"{file_name}.jpg\"\n",
    "            source = os.path.join(SOURCE_DIR, 'Brain Tumor', 'Brain Tumor', file_name)\n",
    "            destination = os.path.join(base_dir, '_MODELLING', 'training', label, file_name)\n",
    "            copyfile(source, destination)\n",
    "\n",
    "        for file_name in val_arr_dict[label]:\n",
    "            file_name = f\"{file_name}.jpg\"\n",
    "            source = os.path.join(SOURCE_DIR, 'Brain Tumor', 'Brain Tumor', file_name)\n",
    "            destination = os.path.join(base_dir, '_MODELLING', 'validation', label, file_name)\n",
    "            copyfile(source, destination)\n",
    "        \n",
    "        for file_name in test_arr_dict[label]:\n",
    "            file_name = f\"{file_name}.jpg\"\n",
    "            source = os.path.join(SOURCE_DIR, 'Brain Tumor', 'Brain Tumor', file_name)\n",
    "            destination = os.path.join(base_dir, '_MODELLING', 'testing', label, file_name)\n",
    "            copyfile(source, destination)\n",
    "    print(f\"Created training, validation and testing directories containing images\")\n",
    "    \n",
    "split_data(base_dir, train_arr_dict, val_arr_dict, test_arr_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the folders contain the data. Data augmentation, and training can be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the generator that already implement data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3009 images belonging to 2 classes.\n",
      "Found 376 images belonging to 2 classes.\n",
      "Found 377 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Loads the data from the directories, preprocesses the images \n",
    "# and creates the generators\n",
    "\n",
    "modelling_base_dir = os.path.join(base_dir, '_MODELLING')\n",
    "os.chdir(modelling_base_dir)\n",
    "\n",
    "def train_val_generators(TRAINING_DIR, VALIDATION_DIR, TEST_DIR):\n",
    "\n",
    "    # Instantiate the ImageDataGenerator class (don't forget to set the arguments to augment the images)\n",
    "    train_datagen = ImageDataGenerator(rescale=1./127.5,\n",
    "                                       rotation_range=30,\n",
    "                                       width_shift_range=0.2,\n",
    "                                       height_shift_range=0.2,\n",
    "                                       shear_range=0.2,\n",
    "                                       zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "    # Pass in the appropriate arguments to the flow_from_directory method\n",
    "    train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
    "                                                      batch_size=32,\n",
    "                                                      class_mode='binary',\n",
    "                                                      target_size=(150, 150))\n",
    "\n",
    "    # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
    "    valid_or_test_datagen = ImageDataGenerator(rescale=1./127.5)\n",
    "\n",
    "    # Pass in the appropriate arguments to the flow_from_directory method\n",
    "    validation_generator = valid_or_test_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
    "                                                                batch_size=32,\n",
    "                                                                class_mode='binary',\n",
    "                                                                target_size=(150, 150))\n",
    "    \n",
    "    test_generator = valid_or_test_datagen.flow_from_directory(directory=TEST_DIR,\n",
    "                                                                batch_size=32,\n",
    "                                                                class_mode='binary',\n",
    "                                                                target_size=(150, 150))\n",
    "    return train_generator, validation_generator, test_generator\n",
    "\n",
    "training_dir = os.path.join(modelling_base_dir, 'training')\n",
    "validation_dir = os.path.join(modelling_base_dir, 'validation')\n",
    "testing_dir = os.path.join(modelling_base_dir, 'testing')\n",
    "\n",
    "train_generator, validation_generator, test_generator = train_val_generators(training_dir, validation_dir, testing_dir)\n",
    "\n",
    "# train generator is a directory iterator, which yields batches of images that are preprocessed with the ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14405/1548671107.py:2: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = tf.keras.applications.MobileNetV2(input_shape=(150, 150, 3),\n"
     ]
    }
   ],
   "source": [
    "# Initiate base model\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(150, 150, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "# Layers of the base model will not be updated during training.\n",
    "base_model.trainable = False\n",
    "\n",
    "# Output layer of the base model becomes inut to additinal custom layer\n",
    "last_output = base_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes output of the base model and adds additional layers on top of it\n",
    "def transfer_learning(last_output, pre_trained_model):\n",
    "    \"\"\"\n",
    "    Applies transfer learning to a pre-trained model by adding custom layers.\n",
    "    Args:\n",
    "        last_output (tf.Tensor): The output tensor from the last layer of the pre-trained model.\n",
    "        pre_trained_model (tf.keras.Model): The pre-trained model to which new layers will be added.\n",
    "    Returns:\n",
    "        tf.keras.Model: A new model with the added custom layers on top of the pre-trained model.\n",
    "    \"\"\"\n",
    "    # Flatten the output layer to 1 dimension\n",
    "    x = tf.keras.layers.Flatten()(last_output)\n",
    "    # Add a fully connected layer with 1024 hidden units and ReLU activation\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "    # Add a dropout rate of 0.6\n",
    "    x = tf.keras.layers.Dropout(0.6)(x)  \n",
    "    # Add a final sigmoid layer for classification\n",
    "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)          \n",
    "    # Create the complete model by using the Model class\n",
    "    model = Model(inputs=pre_trained_model.input, outputs=x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = transfer_learning(last_output, base_model)\n",
    "\n",
    "# stop training if the validation loss does not decrease for 3 consecutive epochs\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# set model configuration\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0003),\n",
    "            loss = 'binary_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/24 16:56:13 INFO mlflow.tracking.fluent: Experiment with name 'Training_Brain_Tumor' does not exist. Creating a new experiment.\n",
      "2024/09/24 16:56:13 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.src.legacy.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n",
      "2024/09/24 16:56:13 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.src.legacy.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maver02/.cache/pypoetry/virtualenvs/image-segmentation-brain-tumor-detection-9DtP8k10-py3.10/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.7627 - loss: 2.7188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 289ms/step - accuracy: 0.7633 - loss: 2.7052 - val_accuracy: 0.8803 - val_loss: 0.3466\n",
      "Epoch 2/5\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.8607 - loss: 0.3781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 283ms/step - accuracy: 0.8608 - loss: 0.3777 - val_accuracy: 0.8564 - val_loss: 0.3414\n",
      "Epoch 3/5\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.8720 - loss: 0.3235"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 284ms/step - accuracy: 0.8720 - loss: 0.3235 - val_accuracy: 0.8617 - val_loss: 0.3297\n",
      "Epoch 4/5\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.8837 - loss: 0.3125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 286ms/step - accuracy: 0.8836 - loss: 0.3124 - val_accuracy: 0.9016 - val_loss: 0.2399\n",
      "Epoch 5/5\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.8914 - loss: 0.2803"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 286ms/step - accuracy: 0.8913 - loss: 0.2804 - val_accuracy: 0.8910 - val_loss: 0.2948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/24 16:58:33 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: '>=' not supported between instances of 'slice' and 'int'\n",
      "2024/09/24 16:58:33 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2024/09/24 16:58:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/09/24 16:58:39 INFO mlflow.tracking._tracking_service.client: 🏃 View run clumsy-colt-467 at: http://127.0.0.1:5000/#/experiments/881152748453209801/runs/6f0a99f66b294038b13df24656fd43ad.\n",
      "2024/09/24 16:58:39 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/881152748453209801.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "# Set our tracking server uri for logging\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"Training_Brain_Tumor\")\n",
    "\n",
    "mlflow.tensorflow.autolog(checkpoint=True, checkpoint_save_best_only=False)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    history = model.fit(train_generator,\n",
    "                        validation_data=validation_generator,\n",
    "                        epochs=5,\n",
    "                        callbacks=[callback])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-segmentation-brain-tumor-detection-9DtP8k10-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
